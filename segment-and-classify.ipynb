{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from torchvision import datasets\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = models.resnet18(pretrained=False)\n",
    "num_classes = len(datasets.ImageFolder(\"food-101/food-101/images\").classes)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Preprocess the image to feed into the model\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Semantic Segmentation Model (DeepLabV3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model = models.segmentation.deeplabv3_resnet101(pretrained=True)\n",
    "seg_model = seg_model.to(device)\n",
    "seg_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segment and Classify Each Segment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def segment_and_classify(image_path, model, seg_model, transform, device):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    original_image = np.array(image)\n",
    "\n",
    "    # Semantic segmentation (DeepLabV3)\n",
    "    input_image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = seg_model(input_image)['out'][0]\n",
    "    \n",
    "    output_predictions = torch.argmax(output, dim=0).cpu().numpy()\n",
    "    \n",
    "    # Convert segmentation to bounding boxes and labels for each segment\n",
    "    labels = np.unique(output_predictions)  # All unique food categories from the segmentation mask\n",
    "    segments = defaultdict(list)\n",
    "    \n",
    "    for label in labels:\n",
    "        # Find pixels for this label\n",
    "        mask = (output_predictions == label)\n",
    "        segment_pixels = np.where(mask)\n",
    "        segments[label].append(segment_pixels)\n",
    "\n",
    "    # Classify each segment and estimate its size\n",
    "    results = []\n",
    "    for label, pixels in segments.items():\n",
    "        # Extract the segment region\n",
    "        y, x = pixels[0], pixels[1]\n",
    "        min_x, max_x = np.min(x), np.max(x)\n",
    "        min_y, max_y = np.min(y), np.max(y)\n",
    "        \n",
    "        # Crop the region of the image\n",
    "        cropped_img = original_image[min_y:max_y+1, min_x:max_x+1]\n",
    "        cropped_img_pil = Image.fromarray(cropped_img)\n",
    "        \n",
    "        # Preprocess cropped image for classification\n",
    "        cropped_img_tensor = transform(cropped_img_pil).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Classify the food segment\n",
    "        with torch.no_grad():\n",
    "            output = model(cropped_img_tensor)\n",
    "            _, predicted_class = torch.max(output, 1)\n",
    "        \n",
    "        # Get the label for the class\n",
    "        class_label = model.fc.classes[predicted_class.item()]\n",
    "        \n",
    "        # Estimate segment size in pixels\n",
    "        segment_area = len(y)  # Pixel count for the segment\n",
    "        results.append({\n",
    "            'food_type': class_label,\n",
    "            'area_pixels': segment_area,\n",
    "            'segment_coords': (min_x, max_x, min_y, max_y)\n",
    "        })\n",
    "    \n",
    "    return results, output_predictions\n",
    "\n",
    "# Function to visualize the segmentation and classification results\n",
    "def visualize_segmentation(image_path, results, output_predictions):\n",
    "    image = Image.open(image_path)\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(image)\n",
    "\n",
    "    for result in results:\n",
    "        food_type = result['food_type']\n",
    "        min_x, max_x, min_y, max_y = result['segment_coords']\n",
    "        rect = patches.Rectangle((min_x, min_y), max_x - min_x, max_y - min_y,\n",
    "                                 linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(min_x, min_y, f\"{food_type}: {result['area_pixels']}px\", color=\"red\", fontsize=12)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(image_path):\n",
    "    results, output_predictions = segment_and_classify(image_path, model, seg_model, transform, device)\n",
    "    visualize_segmentation(image_path, results, output_predictions)\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "image_path = \"path_to_your_image.jpg\"\n",
    "results = main(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meal-analyzer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
